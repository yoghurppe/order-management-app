import streamlit as st
import pandas as pd
import requests
import os
import math
import re

# ðŸŸ¢ ãƒšãƒ¼ã‚¸è¨­å®šã¯ã“ã“ã§æœ€åˆã«å®Ÿè¡Œ
st.set_page_config(page_title="ç®¡ç†è£œåŠ©ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# ðŸŸ¢ ã“ã“ã‹ã‚‰ã‚¢ãƒ—ãƒªã®ä¸­èº«ï¼ˆè¨€èªžé¸æŠžãªã©ï¼‰
language = st.sidebar.selectbox("è¨€èªž / Language", ["æ—¥æœ¬èªž", "ä¸­æ–‡"], key="language")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤ºç”¨ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
TEXT = {
    "æ—¥æœ¬èªž": {
        "title_order_ai": "ç®¡ç†è£œåŠ©ã‚·ã‚¹ãƒ†ãƒ ",
        "mode_select": "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„",
        "upload_csv": "CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "order_ai": "ç™ºæ³¨AIåˆ¤å®š",
        "search_item": "å•†å“æƒ…å ±æ¤œç´¢",
        "upload_item": "å•†å“æƒ…å ±CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "price_improve": "ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ",
        "search_keyword": "å•†å“åãƒ»å•†å“ã‚³ãƒ¼ãƒ‰ã§æ¤œç´¢",
        "search_brand": "ãƒ¡ãƒ¼ã‚«ãƒ¼åã§çµžã‚Šè¾¼ã¿",
        "search_type": "å–æ‰±åŒºåˆ†ã§çµžã‚Šè¾¼ã¿",
        "product_list": "å•†å“ä¸€è¦§",
        "search_keyword": "å•†å“åãƒ»å•†å“ã‚³ãƒ¼ãƒ‰ã§æ¤œç´¢",
        "search_brand": "ãƒ¡ãƒ¼ã‚«ãƒ¼åã§çµžã‚Šè¾¼ã¿",
        "search_type": "å–æ‰±åŒºåˆ†ã§çµžã‚Šè¾¼ã¿",
        "search_rank": "ãƒ©ãƒ³ã‚¯ã§çµžã‚Šè¾¼ã¿",
        "search_code": "å•†å“ã‚³ãƒ¼ãƒ‰ / JAN",
        "all": "ã™ã¹ã¦"
    },
    "ä¸­æ–‡": {
        "title_order_ai": "ç®¡ç†æ”¯æŒç³»ç»Ÿ",
        "mode_select": "è¯·é€‰æ‹©æ¨¡å¼",
        "upload_csv": "ä¸Šä¼ CSV",
        "order_ai": "è®¢è´§AIåˆ¤æ–­",
        "search_item": "å•†å“ä¿¡æ¯æŸ¥è¯¢",
        "upload_item": "ä¸Šä¼ å•†å“ä¿¡æ¯CSV",
        "price_improve": "è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•",
        "search_keyword": "æŒ‰å•†å“åç§°æˆ–ç¼–å·æœç´¢",
        "search_brand": "æŒ‰å“ç‰Œç­›é€‰",
        "search_type": "æŒ‰åˆ†ç±»ç­›é€‰",
        "product_list": "å•†å“åˆ—è¡¨",
        "search_keyword": "æŒ‰å•†å“åç§°æˆ–ç¼–å·æœç´¢",
        "search_brand": "æŒ‰åˆ¶é€ å•†ç­›é€‰",
        "search_type": "æŒ‰åˆ†ç±»ç­›é€‰",
        "search_rank": "æŒ‰ç­‰çº§ç­›é€‰",
        "search_code": "å•†å“ç¼–å· / æ¡ç ",
        "all": "å…¨éƒ¨"
    }
}

# åˆ—åãƒžãƒƒãƒ”ãƒ³ã‚°
COLUMN_NAMES = {
    "æ—¥æœ¬èªž": {
        "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ã‚³ãƒ¼ãƒ‰",
        "jan": "JAN",
        "ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯",
        "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
        "å•†å“å": "å•†å“å",
        "å–æ‰±åŒºåˆ†": "å–æ‰±åŒºåˆ†",
        "åœ¨åº«": "åœ¨åº«",
        "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½",
        "ç™ºæ³¨æ¸ˆ": "ç™ºæ³¨æ¸ˆ",
        "ä»•å…¥ä¾¡æ ¼": "ä»•å…¥ä¾¡æ ¼",
        "ã‚±ãƒ¼ã‚¹å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°",
        "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ",
        "é‡é‡": "é‡é‡(g)"
    },
    "ä¸­æ–‡": {
        "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ç¼–å·",
        "jan": "æ¡ç ",
        "ãƒ©ãƒ³ã‚¯": "ç­‰çº§",
        "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "åˆ¶é€ å•†åç§°",
        "å•†å“å": "å•†å“åç§°",
        "å–æ‰±åŒºåˆ†": "åˆ†ç±»",
        "åœ¨åº«": "åº“å­˜",
        "åˆ©ç”¨å¯èƒ½": "å¯ç”¨åº“å­˜",
        "ç™ºæ³¨æ¸ˆ": "å·²è®¢è´­",
        "ä»•å…¥ä¾¡æ ¼": "è¿›è´§ä»·",
        "ã‚±ãƒ¼ã‚¹å…¥æ•°": "ç®±å…¥æ•°",
        "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "è®¢è´­å•ä½",
        "é‡é‡": "é‡é‡(g)"
    }
}

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.title(TEXT[language]["title_order_ai"])

# ãƒ¢ãƒ¼ãƒ‰é¸æŠžï¼ˆè¨€èªžã«ä¾å­˜ã—ãªã„å†…éƒ¨ã‚­ãƒ¼ã§ç®¡ç†ï¼‰
MODE_KEYS = {
    "home": {
        "æ—¥æœ¬èªž": "ðŸ  ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸",
        "ä¸­æ–‡": "ðŸ  ä¸»é¡µ"
    },
    "search_item": {
        "æ—¥æœ¬èªž": "å•†å“æƒ…å ±æ¤œç´¢",
        "ä¸­æ–‡": "å•†å“ä¿¡æ¯æŸ¥è¯¢"
    },
    "price_improve": {
        "æ—¥æœ¬èªž": "ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ",
        "ä¸­æ–‡": "è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•"
    },
    "order_ai": {
        "æ—¥æœ¬èªž": "ç™ºæ³¨AIåˆ¤å®š",
        "ä¸­æ–‡": "è®¢è´§AIåˆ¤æ–­"
    },
    "csv_upload": {
        "æ—¥æœ¬èªž": "CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "ä¸­æ–‡": "ä¸Šä¼ CSV"
    },
}

mode_labels = [v[language] for v in MODE_KEYS.values()]
mode_selection = st.sidebar.radio(TEXT[language]["mode_select"], mode_labels, index=0)
mode = next(key for key, labels in MODE_KEYS.items() if labels[language] == mode_selection)


# å„ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†åˆ†å²
if mode == "home":
    st.subheader("ðŸ  " + TEXT[language]["title_order_ai"])

    if language == "æ—¥æœ¬èªž":
        st.markdown("""
        #### ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
        å·¦ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
        - ðŸ“¦ ç™ºæ³¨AI
        - ðŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        - ðŸ” å•†å“æƒ…å ±æ¤œç´¢
        - ðŸ’° ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ
        """)
    else:
        st.markdown("""
        #### æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ã€‚
        è¯·ä»Žå·¦ä¾§èœå•ä¸­é€‰æ‹©æ“ä½œæ¨¡å¼ã€‚
        - ðŸ“¦ è®¢è´§AI
        - ðŸ“¤ ä¸Šä¼ CSV
        - ðŸ” å•†å“ä¿¡æ¯æŸ¥è¯¢
        - ðŸ’° è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•
        """)

elif mode == "order_ai":
    st.subheader("ðŸ“¦ ç™ºæ³¨AIãƒ¢ãƒ¼ãƒ‰")

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    def fetch_table(table_name):
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs = []
        offset = 0
        limit = 1000
        while True:
            url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            else:
                return str(x).strip()
        except:
            return ""

    with st.spinner("ðŸ“¦ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        df_sales = fetch_table("sales")
        df_purchase = fetch_table("purchase_data")

    if df_sales.empty or df_purchase.empty:
        st.warning("è²©å£²å®Ÿç¸¾ã¾ãŸã¯ä»•å…¥ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        st.stop()

    df_sales["jan"] = df_sales["jan"].apply(normalize_jan)
    df_purchase["jan"] = df_purchase["jan"].apply(normalize_jan)

    df_sales["quantity_sold"] = pd.to_numeric(df_sales["quantity_sold"], errors="coerce").fillna(0).astype(int)
    df_sales["stock_available"] = pd.to_numeric(df_sales["stock_available"], errors="coerce").fillna(0).astype(int)
    df_sales["stock_ordered"] = pd.to_numeric(df_sales["stock_ordered"], errors="coerce").fillna(0).astype(int)
    df_purchase["order_lot"] = pd.to_numeric(df_purchase["order_lot"], errors="coerce").fillna(0).astype(int)
    df_purchase["price"] = pd.to_numeric(df_purchase["price"], errors="coerce").fillna(0)

    with st.spinner("ðŸ¤– ç™ºæ³¨AIã‚’è¨ˆç®—ä¸­..."):
        results = []
        for _, row in df_sales.iterrows():
            jan = row["jan"]
            sold = row["quantity_sold"]
            stock = row.get("stock_available", 0)
            ordered = row.get("stock_ordered", 0)
            options = df_purchase[df_purchase["jan"] == jan].copy()
            if options.empty:
                continue

            if stock >= sold:
                need_qty = 0
            else:
                need_qty = sold - stock + math.ceil(sold * 0.5) - ordered
                need_qty = max(need_qty, 0)

            if need_qty <= 0:
                continue

            options = options[options["order_lot"] > 0]
            options["diff"] = (options["order_lot"] - need_qty).abs()

            smaller_lots = options[options["order_lot"] <= need_qty]
            if not smaller_lots.empty:
                best_option = smaller_lots.loc[smaller_lots["diff"].idxmin()]
            else:
                near_lots = options[(options["order_lot"] > need_qty) & (options["order_lot"] <= need_qty * 1.5) & (options["order_lot"] != 1)]
                if not near_lots.empty:
                    best_option = near_lots.loc[near_lots["diff"].idxmin()]
                else:
                    one_lot = options[options["order_lot"] == 1]
                    if not one_lot.empty:
                        best_option = one_lot.iloc[0]
                    else:
                        best_option = options.sort_values("order_lot").iloc[0]

            sets = math.ceil(need_qty / best_option["order_lot"])
            qty = sets * best_option["order_lot"]
            total_cost = qty * best_option["price"]

            results.append({
                "jan": jan,
                "è²©å£²å®Ÿç¸¾": sold,
                "åœ¨åº«": stock,
                "ç™ºæ³¨æ¸ˆ": ordered,
                "ç†è«–å¿…è¦æ•°": need_qty,
                "ç™ºæ³¨æ•°": qty,
                "ãƒ­ãƒƒãƒˆ": best_option["order_lot"],
                "æ•°é‡": round(qty / best_option["order_lot"], 2),
                "å˜ä¾¡": best_option["price"],
                "ç·é¡": total_cost,
                "ä»•å…¥å…ˆ": best_option.get("supplier", "ä¸æ˜Ž")
            })

    if results:
        result_df = pd.DataFrame(results)
        column_order = ["jan", "è²©å£²å®Ÿç¸¾", "åœ¨åº«", "ç™ºæ³¨æ¸ˆ", "ç†è«–å¿…è¦æ•°", "ç™ºæ³¨æ•°", "ãƒ­ãƒƒãƒˆ", "æ•°é‡", "å˜ä¾¡", "ç·é¡", "ä»•å…¥å…ˆ"]
        result_df = result_df[[col for col in column_order if col in result_df.columns]]
        st.success(f"âœ… ç™ºæ³¨å¯¾è±¡: {len(result_df)} ä»¶")
        st.dataframe(result_df)

        csv = result_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ðŸ“¥ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="orders_available_based.csv", mime="text/csv")

        st.markdown("---")
        st.subheader("ðŸ“¦ ä»•å…¥å…ˆåˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        for supplier, group in result_df.groupby("ä»•å…¥å…ˆ"):
            supplier_csv = group.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label=f"ðŸ“¥ {supplier} ç”¨ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=supplier_csv,
                file_name=f"orders_{supplier}.csv",
                mime="text/csv"
            )
    else:
        st.info("ç¾åœ¨ã€ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


# ðŸ” å•†å“æƒ…å ±æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ -----------------------------
elif mode == "search_item":
    st.subheader("ðŸ” å•†å“æƒ…å ±æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    # âœ… ã“ã“ã‚’ fetch_table ã¨åŒã˜ãƒãƒƒãƒç‰ˆã«å¤‰æ›´
    def fetch_item_master():
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs = []
        offset, limit = 0, 1000  # Supabase æ—¢å®šã¨åˆã‚ã›ã‚‹
        while True:
            url = f"{SUPABASE_URL}/rest/v1/item_master?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"item_master ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    df_master = fetch_item_master()

    if df_master.empty:
        st.warning("å•†å“æƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    df_master["jan"] = df_master["jan"].astype(str)
    df_master["å•†å“ã‚³ãƒ¼ãƒ‰"] = df_master["å•†å“ã‚³ãƒ¼ãƒ‰"].astype(str)
    df_master["å•†å“å"] = df_master["å•†å“å"].astype(str)

    # --- æ¤œç´¢ UI -------------------------------------------------
    st.subheader(TEXT[language]["search_keyword"])
    keyword_name = st.text_input(TEXT[language]["search_keyword"], "")
    keyword_code = st.text_input(TEXT[language]["search_code"], "")
    
    maker_filter = st.selectbox(
        TEXT[language]["search_brand"],
        [TEXT[language]["all"]] + sorted(df_master["ãƒ¡ãƒ¼ã‚«ãƒ¼å"].dropna().unique())
    )
    
    rank_filter = st.selectbox(
        TEXT[language]["search_rank"],
        [TEXT[language]["all"]] + sorted(df_master["ãƒ©ãƒ³ã‚¯"].dropna().unique())
    )
    
    type_filter = st.selectbox(
        TEXT[language]["search_type"],
        [TEXT[language]["all"]] + sorted(df_master["å–æ‰±åŒºåˆ†"].dropna().unique())
    )
    
    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ------------------------------------------
    df_view = df_master.copy()
    
    # å•†å“åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if keyword_name:
        df_view = df_view[
            df_view["å•†å“å"].str.contains(keyword_name, case=False, na=False)
        ]
    
    # å•†å“ã‚³ãƒ¼ãƒ‰ / JAN ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if keyword_code:
        df_view = df_view[
            df_view["å•†å“ã‚³ãƒ¼ãƒ‰"].str.contains(keyword_code, case=False, na=False) |
            df_view["jan"].str.contains(keyword_code, case=False, na=False)
        ]
    
    # ãƒ¡ãƒ¼ã‚«ãƒ¼å
    if maker_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["ãƒ¡ãƒ¼ã‚«ãƒ¼å"] == maker_filter]
    
    # ãƒ©ãƒ³ã‚¯
    if rank_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["ãƒ©ãƒ³ã‚¯"] == rank_filter]
    
    # å–æ‰±åŒºåˆ†
    if type_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["å–æ‰±åŒºåˆ†"] == type_filter]
    
    # --- ä¸€è¦§è¡¨ç¤º -------------------------------------------------
    view_cols = [
        "å•†å“ã‚³ãƒ¼ãƒ‰", "jan", "ãƒ©ãƒ³ã‚¯", "ãƒ¡ãƒ¼ã‚«ãƒ¼å", "å•†å“å", "å–æ‰±åŒºåˆ†",
        "åœ¨åº«", "åˆ©ç”¨å¯èƒ½", "ç™ºæ³¨æ¸ˆ", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "é‡é‡"
    ]
    available_cols = [col for col in view_cols if col in df_view.columns]

    display_df = df_view[available_cols].sort_values(by="å•†å“ã‚³ãƒ¼ãƒ‰")
    display_df = display_df.rename(columns=COLUMN_NAMES[language])

    st.subheader(TEXT[language]["product_list"])
    st.dataframe(display_df)

    csv = display_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ðŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="item_master_filtered.csv", mime="text/csv")

elif mode == "price_improve":
    st.subheader("ðŸ’° ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒ¢ãƒ¼ãƒ‰")
    
    # ðŸ”§ ã“ã“ã§ HEADERS ã‚’å®šç¾©ã—ã¦ã‹ã‚‰ fetch_table() ã‚’å‘¼ã³å‡ºã™
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    def fetch_table(table_name):
        headers = {**HEADERS, "Prefer": "count=exact"}

    def fetch_table(table_name):
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs = []
        offset = 0
        limit = 1000
        while True:
            url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    with st.spinner("ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        df_sales = fetch_table("sales")
        df_purchase = fetch_table("purchase_data")
        df_item = fetch_table("item_master")

    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            else:
                return str(x).strip()
        except:
            return ""

    df_sales["jan"] = df_sales["jan"].apply(normalize_jan)
    df_purchase["jan"] = df_purchase["jan"].apply(normalize_jan)
    df_item["jan"] = df_item["jan"].apply(normalize_jan)
    df_purchase["price"] = pd.to_numeric(df_purchase["price"], errors="coerce").fillna(0)

    current_prices = {}
    for _, row in df_sales.iterrows():
        jan = row["jan"]
        sold = row["quantity_sold"]
        stock = row.get("stock_available", 0)
        ordered = row.get("stock_ordered", 0)
        options = df_purchase[df_purchase["jan"] == jan].copy()
        if options.empty:
            continue

        if stock >= sold:
            need_qty = 0
        else:
            need_qty = sold - stock + math.ceil(sold * 0.5) - ordered
            need_qty = max(need_qty, 0)

        if need_qty <= 0:
            continue

        options = options[options["order_lot"] > 0]
        options["diff"] = (options["order_lot"] - need_qty).abs()

        smaller_lots = options[options["order_lot"] <= need_qty]
        if not smaller_lots.empty:
            best_option = smaller_lots.loc[smaller_lots["diff"].idxmin()]
        else:
            near_lots = options[(options["order_lot"] > need_qty) & (options["order_lot"] <= need_qty * 1.5) & (options["order_lot"] != 1)]
            if not near_lots.empty:
                best_option = near_lots.loc[near_lots["diff"].idxmin()]
            else:
                one_lot = options[options["order_lot"] == 1]
                if not one_lot.empty:
                    best_option = one_lot.iloc[0]
                else:
                    best_option = options.sort_values("order_lot").iloc[0]

        current_prices[jan] = best_option["price"]

    # æœ€å®‰å€¤å–å¾—
    min_prices = df_purchase.groupby("jan")["price"].min().to_dict()

    rows = []
    for jan, current_price in current_prices.items():
        if jan in min_prices and min_prices[jan] < current_price:
            item = df_item[df_item["jan"] == jan].head(1)
            if not item.empty:
                row = {
                    "å•†å“ã‚³ãƒ¼ãƒ‰": item.iloc[0].get("item_code", ""),
                    "JAN": jan,
                    "ãƒ¡ãƒ¼ã‚«ãƒ¼å": item.iloc[0].get("brand", ""),
                    "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": current_price,
                    "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": min_prices[jan],
                    "å·®åˆ†": round(min_prices[jan] - current_price, 2)
                }
                rows.append(row)

    if rows:
        df_result = pd.DataFrame(rows)
        st.success(f"âœ… æ”¹å–„å¯¾è±¡å•†å“æ•°: {len(df_result)} ä»¶")
        st.dataframe(df_result)
        csv = df_result.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ðŸ“¥ æ”¹å–„ãƒªã‚¹ãƒˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="price_improvement_list.csv", mime="text/csv")
    else:
        st.info("æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹å•†å“ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    if rows:
    df_result = pd.DataFrame(rows)

    # âœ… å¤šè¨€èªžå¯¾å¿œã‚«ãƒ©ãƒ åã«å¤‰æ›
    column_translation = {
        "æ—¥æœ¬èªž": {
            "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ã‚³ãƒ¼ãƒ‰",
            "JAN": "JAN",
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
            "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼",
            "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼",
            "å·®åˆ†": "å·®åˆ†"
        },
        "ä¸­æ–‡": {
            "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ç¼–å·",
            "JAN": "æ¡ç ",
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "åˆ¶é€ å•†åç§°",
            "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": "å½“å‰è¿›è´§ä»·",
            "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": "æœ€ä½Žè¿›è´§ä»·",
            "å·®åˆ†": "å·®é¢"
        }
    }

    df_result = df_result.rename(columns=column_translation[language])

    st.success(f"âœ… æ”¹å–„å¯¾è±¡å•†å“æ•°: {len(df_result)} ä»¶")
    st.dataframe(df_result)


elif mode == "csv_upload":
    st.subheader("ðŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰")

    # ðŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼ˆã¾ãšå…¥åŠ›æ¬„ã‚’è¡¨ç¤ºï¼‰
    input_password = st.text_input("ðŸ”‘ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    correct_password = st.secrets.get("UPLOAD_PASSWORD", "pass1234")

    if input_password != correct_password:
        st.warning("æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            else:
                return str(x).strip()
        except:
            return ""

    def preprocess_csv(df, table):
        df.columns = df.columns.str.strip()
        if table == "sales":
            df.rename(columns={
                "ã‚¢ã‚¤ãƒ†ãƒ ": "jan", "å–æ‰±åŒºåˆ†": "handling_type", "è²©å£²æ•°é‡": "quantity_sold",
                "ç¾åœ¨ã®æ‰‹æŒæ•°é‡": "stock_total", "ç¾åœ¨ã®åˆ©ç”¨å¯èƒ½æ•°é‡": "stock_available", "ç¾åœ¨ã®æ³¨æ–‡æ¸ˆæ•°é‡": "stock_ordered"
            }, inplace=True)
            for col in ["quantity_sold", "stock_total", "stock_available", "stock_ordered"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)
            df["jan"] = df["jan"].apply(normalize_jan)

        elif table == "purchase_data":
            for col in ["order_lot", "price"]:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.replace(",", "")
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
                    if col == "order_lot":
                        df[col] = df[col].round().astype(int)
            df["jan"] = df["jan"].apply(normalize_jan)

        elif table == "item_master":
            df.rename(columns={
                "UPCã‚³ãƒ¼ãƒ‰": "jan", "è¡¨ç¤ºå": "å•†å“å", "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
                "ã‚¢ã‚¤ãƒ†ãƒ å®šç¾©åŽŸä¾¡": "ä»•å…¥ä¾¡æ ¼", "ã‚«ãƒ¼ãƒˆãƒ³å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°",
                "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡(g)": "é‡é‡",
                "æ‰‹æŒ": "åœ¨åº«", "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½", "æ³¨æ–‡æ¸ˆ": "ç™ºæ³¨æ¸ˆ",
                "åå‰": "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯"
            }, inplace=True)
            df.drop(columns=["å†…éƒ¨ID"], inplace=True, errors="ignore")
            df["jan"] = df["jan"].apply(normalize_jan)
            for col in ["ã‚±ãƒ¼ã‚¹å…¥æ•°", "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "åœ¨åº«", "åˆ©ç”¨å¯èƒ½", "ç™ºæ³¨æ¸ˆ"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).round().astype(int)
        return df

    def upload_file(file, table_name):
        if not file:
            return
        with st.spinner(f"ðŸ“¤ {file.name} ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            temp_path = f"/tmp/{file.name}"
            with open(temp_path, "wb") as f:
                f.write(file.read())
            try:
                df = pd.read_csv(temp_path)
                df = preprocess_csv(df, table_name)
                requests.delete(f"{SUPABASE_URL}/rest/v1/{table_name}?id=gt.0", headers=HEADERS)
                if table_name == "purchase_data":
                    df = df.drop_duplicates(subset=["jan", "supplier", "order_lot"], keep="last")
                elif table_name == "item_master":
                    df = df.drop_duplicates(subset=["å•†å“ã‚³ãƒ¼ãƒ‰"], keep="last")
                    if "id" not in df.columns:
                        df.insert(0, "id", range(1, len(df) + 1))
                else:
                    df = df.drop_duplicates(subset=["jan"], keep="last")

                df = df.replace({pd.NA: None, pd.NaT: None, float("nan"): None}).where(pd.notnull(df), None)
                for i in range(0, len(df), 500):
                    batch = df.iloc[i:i+500].to_dict(orient="records")
                    res = requests.post(
                        f"{SUPABASE_URL}/rest/v1/{table_name}",
                        headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                        json=batch
                    )
                    if res.status_code not in [200, 201]:
                        st.error(f"âŒ {table_name} ãƒãƒƒãƒPOSTå¤±æ•—: {res.status_code} {res.text}")
                        return
                st.success(f"âœ… {table_name} ã« {len(df)} ä»¶ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                st.error(f"âŒ {table_name} ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    sales_file = st.file_uploader("ðŸ§¾ sales.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if sales_file:
        upload_file(sales_file, "sales")

    purchase_file = st.file_uploader("ðŸ“¦ purchase_data.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if purchase_file:
        upload_file(purchase_file, "purchase_data")

    item_file = st.file_uploader("ðŸ“‹ item_master.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if item_file:
        upload_file(item_file, "item_master")


