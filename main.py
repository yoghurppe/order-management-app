import streamlit as st
import pandas as pd
import requests
import os
import math
import re
import hashlib
import time
from streamlit_javascript import st_javascript

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ç®¡ç†è£œåŠ©ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# ğŸ”‘ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼ˆMD5ãƒãƒƒã‚·ãƒ¥åŒ–æ¸ˆï¼‰: ä¾‹ã€Œadmin123ã€
PASSWORD_HASH = "0f754d47528b6393d510866d26f508de"  # MD5("smikie0826")

# ğŸ§  ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# ğŸª ã‚¯ãƒƒã‚­ãƒ¼ç¢ºèª
cookie = st_javascript("document.cookie")

# âœ… èªè¨¼æ¸ˆã¿ or ã‚¯ãƒƒã‚­ãƒ¼æœ‰åŠ¹ãªã‚‰ã‚¹ãƒ«ãƒ¼
if st.session_state.authenticated or ("auth_token=valid" in str(cookie)):
    st.session_state.authenticated = True

    # ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆæ©Ÿèƒ½ï¼ˆã‚¯ãƒƒã‚­ãƒ¼å‰Šé™¤ + ãƒªãƒ­ãƒ¼ãƒ‰ï¼‰
    if st.sidebar.button("ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
        st.session_state.authenticated = False
        st_javascript("document.cookie = 'auth_token=; Max-Age=0'; location.reload();")

else:
    st.title("ğŸ” èªè¨¼ãŒå¿…è¦ã§ã™")

    # âœ… ã‚¨ãƒ³ã‚¿ãƒ¼ã‚­ãƒ¼å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("login_form"):
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", type="password")
        submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")

    if submitted:
        hashed = hashlib.md5(password.encode()).hexdigest()
        if hashed == PASSWORD_HASH:
            st.session_state.authenticated = True
            st_javascript("document.cookie = 'auth_token=valid; Max-Age=86400'")
            st.success("âœ… èªè¨¼æˆåŠŸã€ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")
            time.sleep(1)
            st.experimental_rerun()
        else:
            st.error("âŒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")

    st.stop()
    
# ğŸŸ¢ ã“ã“ã‹ã‚‰ã‚¢ãƒ—ãƒªã®ä¸­èº«ï¼ˆè¨€èªé¸æŠãªã©ï¼‰
language = st.sidebar.selectbox("è¨€èª / Language", ["æ—¥æœ¬èª", "ä¸­æ–‡"], key="language")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤ºç”¨ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
TEXT = {
    "æ—¥æœ¬èª": {
        "title_order_ai": "ç®¡ç†è£œåŠ©ã‚·ã‚¹ãƒ†ãƒ ",
        "mode_select": "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„",
        "upload_csv": "CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "order_ai": "ç™ºæ³¨AIåˆ¤å®š",
        "search_item": "å•†å“æƒ…å ±æ¤œç´¢",
        "upload_item": "å•†å“æƒ…å ±CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "price_improve": "ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ",
        "search_keyword": "å•†å“åãƒ»å•†å“ã‚³ãƒ¼ãƒ‰ã§æ¤œç´¢",
        "search_brand": "ãƒ¡ãƒ¼ã‚«ãƒ¼åã§çµã‚Šè¾¼ã¿",
        "search_type": "å–æ‰±åŒºåˆ†ã§çµã‚Šè¾¼ã¿",
        "product_list": "å•†å“ä¸€è¦§",
        "search_keyword": "å•†å“åãƒ»å•†å“ã‚³ãƒ¼ãƒ‰ã§æ¤œç´¢",
        "search_brand": "ãƒ¡ãƒ¼ã‚«ãƒ¼åã§çµã‚Šè¾¼ã¿",
        "search_type": "å–æ‰±åŒºåˆ†ã§çµã‚Šè¾¼ã¿",
        "search_rank": "ãƒ©ãƒ³ã‚¯ã§çµã‚Šè¾¼ã¿",
        "search_code": "å•†å“ã‚³ãƒ¼ãƒ‰ / JAN",
        "all": "ã™ã¹ã¦",
        "loading_data": "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."
    },
    "ä¸­æ–‡": {
        "title_order_ai": "ç®¡ç†æ”¯æŒç³»ç»Ÿ",
        "mode_select": "è¯·é€‰æ‹©æ¨¡å¼",
        "upload_csv": "ä¸Šä¼ CSV",
        "order_ai": "è®¢è´§AIåˆ¤æ–­",
        "search_item": "å•†å“ä¿¡æ¯æŸ¥è¯¢",
        "upload_item": "ä¸Šä¼ å•†å“ä¿¡æ¯CSV",
        "price_improve": "è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•",
        "search_keyword": "æŒ‰å•†å“åç§°æˆ–ç¼–å·æœç´¢",
        "search_brand": "æŒ‰å“ç‰Œç­›é€‰",
        "search_type": "æŒ‰åˆ†ç±»ç­›é€‰",
        "product_list": "å•†å“åˆ—è¡¨",
        "search_keyword": "æŒ‰å•†å“åç§°æˆ–ç¼–å·æœç´¢",
        "search_brand": "æŒ‰åˆ¶é€ å•†ç­›é€‰",
        "search_type": "æŒ‰åˆ†ç±»ç­›é€‰",
        "search_rank": "æŒ‰ç­‰çº§ç­›é€‰",
        "search_code": "å•†å“ç¼–å· / æ¡ç ",
        "all": "å…¨éƒ¨",
        "loading_data": "ğŸ“Š æ­£åœ¨è¯»å–æ•°æ®..."
    }
}

# åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°
COLUMN_NAMES = {
    "æ—¥æœ¬èª": {
        "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ã‚³ãƒ¼ãƒ‰",
        "jan": "JAN",
        "ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯",
        "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
        "å•†å“å": "å•†å“å",
        "å–æ‰±åŒºåˆ†": "å–æ‰±åŒºåˆ†",
        "åœ¨åº«": "åœ¨åº«",
        "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½",
        "ç™ºæ³¨æ¸ˆ": "ç™ºæ³¨æ¸ˆ",
        "ä»•å…¥ä¾¡æ ¼": "ä»•å…¥ä¾¡æ ¼",
        "ã‚±ãƒ¼ã‚¹å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°",
        "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ",
        "é‡é‡": "é‡é‡(g)"
    },
    "ä¸­æ–‡": {
        "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ç¼–å·",
        "jan": "æ¡ç ",
        "ãƒ©ãƒ³ã‚¯": "ç­‰çº§",
        "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "åˆ¶é€ å•†åç§°",
        "å•†å“å": "å•†å“åç§°",
        "å–æ‰±åŒºåˆ†": "åˆ†ç±»",
        "åœ¨åº«": "åº“å­˜",
        "åˆ©ç”¨å¯èƒ½": "å¯ç”¨åº“å­˜",
        "ç™ºæ³¨æ¸ˆ": "å·²è®¢è´­",
        "ä»•å…¥ä¾¡æ ¼": "è¿›è´§ä»·",
        "ã‚±ãƒ¼ã‚¹å…¥æ•°": "ç®±å…¥æ•°",
        "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "è®¢è´­å•ä½",
        "é‡é‡": "é‡é‡(g)"
    }
}

# ğŸ” item_master æœ€æ–°æ›´æ–°æ—¥ã‚’å–å¾—ï¼ˆsidebarè¡¨ç¤ºç”¨ï¼‰
SUPABASE_URL_PRE = st.secrets["SUPABASE_URL"]
SUPABASE_KEY_PRE = st.secrets["SUPABASE_KEY"]
HEADERS_PRE = {
    "apikey": SUPABASE_KEY_PRE,
    "Authorization": f"Bearer {SUPABASE_KEY_PRE}",
    "Content-Type": "application/json"
}

def fetch_latest_item_update():
    url = f"{SUPABASE_URL_PRE}/rest/v1/item_master?select=updated_at&order=updated_at.desc&limit=1"
    res = requests.get(url, headers=HEADERS_PRE)
    if res.status_code == 200 and res.json():
        dt = pd.to_datetime(res.json()[0]["updated_at"], errors="coerce")
        if pd.notnull(dt):
            return f"ï¼ˆ{dt.strftime('%-m.%d update')}ï¼‰"
    return ""

item_master_update_text = fetch_latest_item_update()

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.title(TEXT[language]["title_order_ai"])

# ãƒ¢ãƒ¼ãƒ‰é¸æŠï¼ˆè¨€èªã«ä¾å­˜ã—ãªã„å†…éƒ¨ã‚­ãƒ¼ã§ç®¡ç†ï¼‰
MODE_KEYS = {
    "home": {
        "æ—¥æœ¬èª": "ğŸ  ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸",
        "ä¸­æ–‡": "ğŸ  ä¸»é¡µ"
    },
    "search_item": {
        "æ—¥æœ¬èª": f"ğŸ” å•†å“æƒ…å ±æ¤œç´¢{item_master_update_text}",
        "ä¸­æ–‡": f"ğŸ” å•†å“ä¿¡æ¯æŸ¥è¯¢{item_master_update_text}"
    },
    "price_improve": {
        "æ—¥æœ¬èª": "ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ",
        "ä¸­æ–‡": "è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•"
    },
    "order_ai": {
        "æ—¥æœ¬èª": "ç™ºæ³¨AIåˆ¤å®š",
        "ä¸­æ–‡": "è®¢è´§AIåˆ¤æ–­"
    },
    "csv_upload": {
        "æ—¥æœ¬èª": "CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "ä¸­æ–‡": "ä¸Šä¼ CSV"
    },
}

mode_labels = [v[language] for v in MODE_KEYS.values()]
mode_selection = st.sidebar.radio(TEXT[language]["mode_select"], mode_labels, index=0)
mode = next(key for key, labels in MODE_KEYS.items() if labels[language] == mode_selection)


# å„ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†åˆ†å²
if mode == "home":
    st.subheader("ğŸ  " + TEXT[language]["title_order_ai"])

    if language == "æ—¥æœ¬èª":
        st.markdown("""
        #### ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
        å·¦ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
        - ğŸ“¦ ç™ºæ³¨AI
        - ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        - ğŸ” å•†å“æƒ…å ±æ¤œç´¢
        - ğŸ’° ä»•å…¥ä¾¡æ ¼æ”¹å–„ãƒªã‚¹ãƒˆ
        """)
    else:
        st.markdown("""
        #### æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ã€‚
        è¯·ä»å·¦ä¾§èœå•ä¸­é€‰æ‹©æ“ä½œæ¨¡å¼ã€‚
        - ğŸ“¦ è®¢è´§AI
        - ğŸ“¤ ä¸Šä¼ CSV
        - ğŸ” å•†å“ä¿¡æ¯æŸ¥è¯¢
        - ğŸ’° è¿›è´§ä»·æ ¼ä¼˜åŒ–æ¸…å•
        """)

elif mode == "order_ai":
    st.subheader("ğŸ“¦ ç™ºæ³¨AIãƒ¢ãƒ¼ãƒ‰")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ› æ¥ç¶šæƒ…å ±
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ“¥ ãƒ†ãƒ¼ãƒ–ãƒ«å…¨ä»¶å–å¾—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    def fetch_table(table_name):
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs, offset, limit = [], 0, 1000
        while True:
            url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ”§ JAN æ­£è¦åŒ–
    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            return str(x).strip()
        except Exception:
            return ""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ“¤ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with st.spinner("ğŸ“¦ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        df_sales    = fetch_table("sales")
        df_purchase = fetch_table("purchase_data")
        df_master   = fetch_table("item_master")

    if df_sales.empty or df_purchase.empty or df_master.empty:
        st.warning("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        st.stop()

    # æ­£è¦åŒ–
    for df in (df_sales, df_purchase, df_master):
        df["jan"] = df["jan"].apply(normalize_jan)

    # å‹å¤‰æ›
    df_sales["quantity_sold"]  = pd.to_numeric(df_sales["quantity_sold"],  errors="coerce").fillna(0).astype(int)
    df_sales["stock_available"] = pd.to_numeric(df_sales["stock_available"], errors="coerce").fillna(0).astype(int)
    df_sales["stock_ordered"]  = pd.to_numeric(df_sales["stock_ordered"],   errors="coerce").fillna(0).astype(int)
    df_purchase["order_lot"]   = pd.to_numeric(df_purchase["order_lot"],    errors="coerce").fillna(0).astype(int)
    df_purchase["price"]       = pd.to_numeric(df_purchase["price"],        errors="coerce").fillna(0)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ·ï¸ ãƒ©ãƒ³ã‚¯åˆ—ã‚’ sales ã«ä»˜ä¸
    df_sales = pd.merge(
        df_sales,
        df_master[["jan", "ãƒ©ãƒ³ã‚¯"]],
        on="jan",
        how="left"
    )

    # ãƒ©ãƒ³ã‚¯ â†’ å€ç‡
    RANK_FACTOR = {
        "Aãƒ©ãƒ³ã‚¯": 1.5,
        "Bãƒ©ãƒ³ã‚¯": 1.2,
        "Cãƒ©ãƒ³ã‚¯": 1.0,
        "TEST":   1.5
    }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ¤– ç™ºæ³¨AIãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    with st.spinner("ğŸ¤– ç™ºæ³¨AIãŒè¨ˆç®—ã‚’ã—ã¦ã„ã¾ã™..."):
        results = []
        for _, row in df_sales.iterrows():
            jan     = row["jan"]
            sold    = row["quantity_sold"]
            stock   = row["stock_available"]
            ordered = row["stock_ordered"]

            # ãƒ©ãƒ³ã‚¯å–å¾—ï¼†æ­£è¦åŒ–
            raw_rank = str(row.get("ãƒ©ãƒ³ã‚¯", "")).strip()
            if raw_rank and raw_rank[-2:] != "ãƒ©ãƒ³ã‚¯" and raw_rank.upper() in ["A", "B", "C"]:
                raw_rank = f"{raw_rank.upper()}ãƒ©ãƒ³ã‚¯"
            factor = RANK_FACTOR.get(raw_rank, 1.0)

            # 1â€¯ã‹æœˆåˆ† Ã— å€ç‡
            raw_need = sold - stock - ordered
            need_qty = max(math.ceil(raw_need * factor), 0)
            if need_qty == 0:
                continue

            options = df_purchase[df_purchase["jan"] == jan].copy()
            options = options[options["order_lot"] > 0]
            if options.empty:
                continue

            # â”€ ãƒ­ãƒƒãƒˆé¸æŠãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰ â”€
            options["diff"] = (options["order_lot"] - need_qty).abs()
            smaller = options[options["order_lot"] <= need_qty]
            if not smaller.empty:
                best = smaller.loc[smaller["diff"].idxmin()]
            else:
                near = options[(options["order_lot"] > need_qty) &
                               (options["order_lot"] <= need_qty * 1.5) &
                               (options["order_lot"] != 1)]
                if not near.empty:
                    best = near.loc[near["diff"].idxmin()]
                else:
                    one  = options[options["order_lot"] == 1]
                    best = one.iloc[0] if not one.empty else options.sort_values("order_lot").iloc[0]

            sets       = math.ceil(need_qty / best["order_lot"])
            qty        = sets * best["order_lot"]
            total_cost = qty * best["price"]

            results.append({
                "jan": jan,
                "ãƒ©ãƒ³ã‚¯": raw_rank,
                "è²©å£²å®Ÿç¸¾": sold,
                "åœ¨åº«": stock,
                "ç™ºæ³¨æ¸ˆ": ordered,
                "ç†è«–å¿…è¦æ•°": need_qty,
                "ç™ºæ³¨æ•°": qty,
                "ãƒ­ãƒƒãƒˆ": best["order_lot"],
                "æ•°é‡": round(qty / best["order_lot"], 2),
                "å˜ä¾¡": best["price"],
                "ç·é¡": total_cost,
                "ä»•å…¥å…ˆ": best.get("supplier", "ä¸æ˜")
            })

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ“Š çµæœå‡ºåŠ›
    if results:
        result_df = pd.DataFrame(results)

        # å•†å“åãƒ»å–æ‰±åŒºåˆ†ã‚’ä»˜ä¸
        result_df = pd.merge(
            result_df,
            df_master[["jan", "å•†å“å", "å–æ‰±åŒºåˆ†", "ãƒ©ãƒ³ã‚¯"]],
            on="jan",
            how="left"
        )

        # ãƒ•ã‚£ãƒ«ã‚¿
        result_df = result_df[result_df["å•†å“å"].notna()]
        result_df = result_df[result_df["å–æ‰±åŒºåˆ†"] != "å–æ‰±ä¸­æ­¢"]

        # åˆ—é †
        column_order = [
            "jan", "å•†å“å", "ãƒ©ãƒ³ã‚¯",
            "è²©å£²å®Ÿç¸¾", "åœ¨åº«", "ç™ºæ³¨æ¸ˆ",
            "ç†è«–å¿…è¦æ•°", "ç™ºæ³¨æ•°", "ãƒ­ãƒƒãƒˆ", "æ•°é‡",
            "å˜ä¾¡", "ç·é¡", "ä»•å…¥å…ˆ"
        ]
        result_df = result_df[[col for col in column_order if col in result_df.columns]]

        # ç”»é¢è¡¨ç¤º
        st.success(f"âœ… ç™ºæ³¨å¯¾è±¡: {len(result_df)} ä»¶")
        st.dataframe(result_df)

        # å…¨ä½“ CSV
        csv = result_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv,
                           file_name="orders_available_based.csv", mime="text/csv")

        # ä»•å…¥å…ˆåˆ¥ CSV
        st.markdown("---")
        st.subheader("ğŸ“¦ ä»•å…¥å…ˆåˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        for supplier, group in result_df.groupby("ä»•å…¥å…ˆ"):
            sup_csv = group.to_csv(index=False).encode("utf-8-sig")
            st.download_button(label=f"ğŸ“¥ {supplier} ç”¨ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                               data=sup_csv,
                               file_name=f"orders_{supplier}.csv",
                               mime="text/csv")
    else:
        st.info("ç¾åœ¨ã€ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")



# ğŸ” å•†å“æƒ…å ±æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ -----------------------------
elif mode == "search_item":
    st.subheader("ğŸ” å•†å“æƒ…å ±æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    # âœ… ã“ã“ã‚’ fetch_table ã¨åŒã˜ãƒãƒƒãƒç‰ˆã«å¤‰æ›´
    def fetch_item_master():
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs = []
        offset, limit = 0, 1000  # Supabase æ—¢å®šã¨åˆã‚ã›ã‚‹
        while True:
            url = f"{SUPABASE_URL}/rest/v1/item_master?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"item_master ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    df_master = fetch_item_master()

    if df_master.empty:
        st.warning("å•†å“æƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    df_master["jan"] = df_master["jan"].astype(str)
    df_master["å•†å“ã‚³ãƒ¼ãƒ‰"] = df_master["å•†å“ã‚³ãƒ¼ãƒ‰"].astype(str)
    df_master["å•†å“å"] = df_master["å•†å“å"].astype(str)

    # --- æ¤œç´¢ UI -------------------------------------------------
    st.subheader(TEXT[language]["search_keyword"])
    keyword_name = st.text_input(TEXT[language]["search_keyword"], "")
    keyword_code = st.text_input(TEXT[language]["search_code"], "")
    
    maker_filter = st.selectbox(
        TEXT[language]["search_brand"],
        [TEXT[language]["all"]] + sorted(df_master["ãƒ¡ãƒ¼ã‚«ãƒ¼å"].dropna().unique())
    )
    
    rank_filter = st.selectbox(
        TEXT[language]["search_rank"],
        [TEXT[language]["all"]] + sorted(df_master["ãƒ©ãƒ³ã‚¯"].dropna().unique())
    )
    
    type_filter = st.selectbox(
        TEXT[language]["search_type"],
        [TEXT[language]["all"]] + sorted(df_master["å–æ‰±åŒºåˆ†"].dropna().unique())
    )
    
    # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ------------------------------------------
    df_view = df_master.copy()
    
    # å•†å“åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if keyword_name:
        df_view = df_view[
            df_view["å•†å“å"].str.contains(keyword_name, case=False, na=False)
        ]
    
    # å•†å“ã‚³ãƒ¼ãƒ‰ / JAN ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if keyword_code:
        df_view = df_view[
            df_view["å•†å“ã‚³ãƒ¼ãƒ‰"].str.contains(keyword_code, case=False, na=False) |
            df_view["jan"].str.contains(keyword_code, case=False, na=False)
        ]
    
    # ãƒ¡ãƒ¼ã‚«ãƒ¼å
    if maker_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["ãƒ¡ãƒ¼ã‚«ãƒ¼å"] == maker_filter]
    
    # ãƒ©ãƒ³ã‚¯
    if rank_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["ãƒ©ãƒ³ã‚¯"] == rank_filter]
    
    # å–æ‰±åŒºåˆ†
    if type_filter != TEXT[language]["all"]:
        df_view = df_view[df_view["å–æ‰±åŒºåˆ†"] == type_filter]
    
    # --- ä¸€è¦§è¡¨ç¤º -------------------------------------------------
    view_cols = [
        "å•†å“ã‚³ãƒ¼ãƒ‰", "jan", "ãƒ©ãƒ³ã‚¯", "ãƒ¡ãƒ¼ã‚«ãƒ¼å", "å•†å“å", "å–æ‰±åŒºåˆ†",
        "åœ¨åº«", "åˆ©ç”¨å¯èƒ½", "ç™ºæ³¨æ¸ˆ", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "é‡é‡"
    ]
    available_cols = [col for col in view_cols if col in df_view.columns]

    display_df = df_view[available_cols].sort_values(by="å•†å“ã‚³ãƒ¼ãƒ‰")
    display_df = display_df.rename(columns=COLUMN_NAMES[language])

    st.subheader(TEXT[language]["product_list"])
    st.dataframe(display_df)

    csv = display_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="item_master_filtered.csv", mime="text/csv")

elif mode == "price_improve":
    st.subheader("ğŸ’° " + TEXT[language]["price_improve"])

    # èªè¨¼ç”¨ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    def fetch_table(table_name):
        headers = {**HEADERS, "Prefer": "count=exact"}
        dfs = []
        offset = 0
        limit = 1000
        while True:
            url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*&offset={offset}&limit={limit}"
            res = requests.get(url, headers=headers)
            if res.status_code == 416 or not res.json():
                break
            if res.status_code not in [200, 206]:
                st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
                return pd.DataFrame()
            dfs.append(pd.DataFrame(res.json()))
            offset += limit
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    with st.spinner("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        df_sales = fetch_table("sales")
        df_purchase = fetch_table("purchase_data")
        df_item = fetch_table("item_master")

    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            else:
                return str(x).strip()
        except:
            return ""

    # æ•´å½¢
    df_sales["jan"] = df_sales["jan"].apply(normalize_jan)
    df_purchase["jan"] = df_purchase["jan"].apply(normalize_jan)
    df_item["jan"] = df_item["jan"].apply(normalize_jan)
    df_purchase["price"] = pd.to_numeric(df_purchase["price"], errors="coerce").fillna(0)

    # ç¾åœ¨ä¾¡æ ¼åˆ¤å®š
    current_prices = {}
    for _, row in df_sales.iterrows():
        jan = row["jan"]
        sold = row["quantity_sold"]
        stock = row.get("stock_available", 0)
        ordered = row.get("stock_ordered", 0)
        options = df_purchase[df_purchase["jan"] == jan].copy()
        if options.empty:
            continue

        if stock >= sold:
            need_qty = 0
        else:
            need_qty = sold - stock + math.ceil(sold * 0.5) - ordered
            need_qty = max(need_qty, 0)

        if need_qty <= 0:
            continue

        options = options[options["order_lot"] > 0]
        options["diff"] = (options["order_lot"] - need_qty).abs()

        smaller_lots = options[options["order_lot"] <= need_qty]
        if not smaller_lots.empty:
            best_option = smaller_lots.loc[smaller_lots["diff"].idxmin()]
        else:
            near_lots = options[(options["order_lot"] > need_qty) & (options["order_lot"] <= need_qty * 1.5) & (options["order_lot"] != 1)]
            if not near_lots.empty:
                best_option = near_lots.loc[near_lots["diff"].idxmin()]
            else:
                one_lot = options[options["order_lot"] == 1]
                if not one_lot.empty:
                    best_option = one_lot.iloc[0]
                else:
                    best_option = options.sort_values("order_lot").iloc[0]

        current_prices[jan] = best_option["price"]

    # æœ€å®‰å€¤å–å¾—
    min_prices = df_purchase.groupby("jan")["price"].min().to_dict()

    rows = []
    for jan, current_price in current_prices.items():
        if jan in min_prices and min_prices[jan] < current_price:
            item = df_item[df_item["jan"] == jan].head(1)
            if not item.empty:
                row = {
                    "å•†å“ã‚³ãƒ¼ãƒ‰": item.iloc[0].get("item_code", ""),
                    "JAN": jan,
                    "ãƒ¡ãƒ¼ã‚«ãƒ¼å": item.iloc[0].get("brand", ""),
                    "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": current_price,
                    "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": min_prices[jan],
                    "å·®åˆ†": round(min_prices[jan] - current_price, 2)
                }
                rows.append(row)

    if rows:
        df_result = pd.DataFrame(rows)

        # âœ… å¤šè¨€èªã‚«ãƒ©ãƒ åã«å¤‰æ›
        column_translation = {
            "æ—¥æœ¬èª": {
                "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ã‚³ãƒ¼ãƒ‰",
                "JAN": "JAN",
                "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
                "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼",
                "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼",
                "å·®åˆ†": "å·®åˆ†"
            },
            "ä¸­æ–‡": {
                "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ç¼–å·",
                "JAN": "æ¡ç ",
                "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "åˆ¶é€ å•†åç§°",
                "ç¾åœ¨ã®ä»•å…¥ä¾¡æ ¼": "å½“å‰è¿›è´§ä»·",
                "æœ€å®‰å€¤ã®ä»•å…¥ä¾¡æ ¼": "æœ€ä½è¿›è´§ä»·",
                "å·®åˆ†": "å·®é¢"
            }
        }

        df_result = df_result.rename(columns=column_translation[language])

        st.success(f"âœ… æ”¹å–„å¯¾è±¡å•†å“æ•°: {len(df_result)} ä»¶")
        st.dataframe(df_result)

        csv = df_result.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ æ”¹å–„ãƒªã‚¹ãƒˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="price_improvement_list.csv",
            mime="text/csv",
            key="price_improve_download"  # ğŸ”‘ è¤‡æ•°å‘¼ã³å‡ºã—é˜²æ­¢
        )
    else:
        st.info("æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹å•†å“ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


elif mode == "csv_upload":
    st.subheader("ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰")

    # ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼ˆã¾ãšå…¥åŠ›æ¬„ã‚’è¡¨ç¤ºï¼‰
    input_password = st.text_input("ğŸ”‘ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    correct_password = st.secrets.get("UPLOAD_PASSWORD", "pass1234")

    if input_password != correct_password:
        st.warning("æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    HEADERS = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json"
    }

    def normalize_jan(x):
        try:
            if re.fullmatch(r"\d+(\.0+)?", str(x)):
                return str(int(float(x)))
            else:
                return str(x).strip()
        except:
            return ""

    def preprocess_csv(df, table):
        df.columns = df.columns.str.strip()
        if table == "sales":
            df.rename(columns={
                "ã‚¢ã‚¤ãƒ†ãƒ ": "jan", "å–æ‰±åŒºåˆ†": "handling_type", "è²©å£²æ•°é‡": "quantity_sold",
                "ç¾åœ¨ã®æ‰‹æŒæ•°é‡": "stock_total", "ç¾åœ¨ã®åˆ©ç”¨å¯èƒ½æ•°é‡": "stock_available", "ç¾åœ¨ã®æ³¨æ–‡æ¸ˆæ•°é‡": "stock_ordered"
            }, inplace=True)
            for col in ["quantity_sold", "stock_total", "stock_available", "stock_ordered"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)
            df["jan"] = df["jan"].apply(normalize_jan)

        elif table == "purchase_data":
            for col in ["order_lot", "price"]:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.replace(",", "")
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
                    if col == "order_lot":
                        df[col] = df[col].round().astype(int)
            df["jan"] = df["jan"].apply(normalize_jan)

        elif table == "item_master":
            df.rename(columns={
                "UPCã‚³ãƒ¼ãƒ‰": "jan", "è¡¨ç¤ºå": "å•†å“å", "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ¡ãƒ¼ã‚«ãƒ¼å",
                "ã‚¢ã‚¤ãƒ†ãƒ å®šç¾©åŸä¾¡": "ä»•å…¥ä¾¡æ ¼", "ã‚«ãƒ¼ãƒˆãƒ³å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°",
                "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡(g)": "é‡é‡",
                "æ‰‹æŒ": "åœ¨åº«", "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½", "æ³¨æ–‡æ¸ˆ": "ç™ºæ³¨æ¸ˆ",
                "åå‰": "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯"
            }, inplace=True)
            df.drop(columns=["å†…éƒ¨ID"], inplace=True, errors="ignore")
            df["jan"] = df["jan"].apply(normalize_jan)
            for col in ["ã‚±ãƒ¼ã‚¹å…¥æ•°", "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "åœ¨åº«", "åˆ©ç”¨å¯èƒ½", "ç™ºæ³¨æ¸ˆ"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).round().astype(int)
        return df

    def upload_file(file, table_name):
        if not file:
            return
        with st.spinner(f"ğŸ“¤ {file.name} ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            temp_path = f"/tmp/{file.name}"
            with open(temp_path, "wb") as f:
                f.write(file.read())
            try:
                df = pd.read_csv(temp_path)
                df = preprocess_csv(df, table_name)
                requests.delete(f"{SUPABASE_URL}/rest/v1/{table_name}?id=gt.0", headers=HEADERS)
                if table_name == "purchase_data":
                    df = df.drop_duplicates(subset=["jan", "supplier", "order_lot"], keep="last")
                elif table_name == "item_master":
                    df = df.drop_duplicates(subset=["å•†å“ã‚³ãƒ¼ãƒ‰"], keep="last")
                    if "id" not in df.columns:
                        df.insert(0, "id", range(1, len(df) + 1))
                else:
                    df = df.drop_duplicates(subset=["jan"], keep="last")

                df = df.replace({pd.NA: None, pd.NaT: None, float("nan"): None}).where(pd.notnull(df), None)
                for i in range(0, len(df), 500):
                    batch = df.iloc[i:i+500].to_dict(orient="records")
                    res = requests.post(
                        f"{SUPABASE_URL}/rest/v1/{table_name}",
                        headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                        json=batch
                    )
                    if res.status_code not in [200, 201]:
                        st.error(f"âŒ {table_name} ãƒãƒƒãƒPOSTå¤±æ•—: {res.status_code} {res.text}")
                        return
                st.success(f"âœ… {table_name} ã« {len(df)} ä»¶ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                st.error(f"âŒ {table_name} ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    sales_file = st.file_uploader("ğŸ§¾ sales.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if sales_file:
        upload_file(sales_file, "sales")

    purchase_file = st.file_uploader("ğŸ“¦ purchase_data.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if purchase_file:
        upload_file(purchase_file, "purchase_data")

    item_file = st.file_uploader("ğŸ“‹ item_master.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if item_file:
        upload_file(item_file, "item_master")


