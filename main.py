import streamlit as st
import pandas as pd
import requests
import os
import json

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–¢æ•°ï¼ˆæœ€é©åŒ–ï¼‰ ---
def batch_upload_csv_to_supabase(file_path, table):
    if not os.path.exists(file_path):
        st.warning(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return
    try:
        df = pd.read_csv(file_path)

        if table == "sales":
            rename_cols = {
                "ã‚¢ã‚¤ãƒ†ãƒ ": "jan",
                "è²©å£²æ•°é‡": "quantity_sold",
                "ç¾åœ¨ã®æ‰‹æŒæ•°é‡": "stock_total",
                "ç¾åœ¨ã®åˆ©ç”¨å¯èƒ½æ•°é‡": "stock_available",
                "ç¾åœ¨ã®æ³¨æ–‡æ¸ˆæ•°é‡": "stock_ordered"
            }
            df.rename(columns=rename_cols, inplace=True)

            for col in ["quantity_sold", "stock_total", "stock_available", "stock_ordered"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).round().astype(int)

            df["jan"] = df["jan"].astype(str).str.strip()

        if table == "purchase_data":
            for col in ["order_lot", "price"]:
                if col in df.columns:
                    df[col] = (df[col].astype(str).str.replace(",", "")
                                    .pipe(pd.to_numeric, errors="coerce")
                                    .fillna(0))
                    if col == "order_lot":
                        df[col] = df[col].round().astype(int)

            if "jan" in df.columns:
                df["jan"] = pd.to_numeric(df["jan"], errors="coerce").fillna(0).astype("int64").astype(str).str.strip()

            # ğŸ” å…¨å‰Šé™¤ï¼ˆä¸Šæ›¸ãå‹•ä½œï¼‰
            del_res = requests.delete(f"{SUPABASE_URL}/rest/v1/purchase_data", headers=HEADERS)
            if del_res.status_code not in [200, 204]:
                st.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ã«å¤±æ•—: {del_res.status_code} {del_res.text}")
                return

        df = df.drop_duplicates(subset=["jan", "supplier"] if "supplier" in df.columns else "jan", keep="last")

        st.info(f"ğŸ”„ {table} ã« {len(df)} ä»¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        progress = st.progress(0)
        batch_size = 500
        total = len(df)

        for i in range(0, total, batch_size):
            batch = df.iloc[i:i+batch_size].where(pd.notnull(df.iloc[i:i+batch_size]), None).to_dict(orient="records")
            res = requests.post(
                f"{SUPABASE_URL}/rest/v1/{table}",
                headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                json=batch
            )
            if res.status_code not in [200, 201]:
                st.error(f"âŒ ãƒãƒƒãƒPOSTå¤±æ•— ({i} ä»¶ç›®ã€œ): {res.status_code} {res.text}")
                return
            progress.progress(min((i + batch_size) / total, 1.0))

        st.success(f"âœ… {table} ãƒ†ãƒ¼ãƒ–ãƒ«ã« {total} ä»¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"âŒ {table} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
