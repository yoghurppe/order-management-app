import streamlit as st
import pandas as pd
import requests
import os
import json

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ ---
mode = st.sidebar.radio("æ“ä½œã‚’é¸æŠ", ["ğŸ“¦ ç™ºæ³¨ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“š å•†å“æƒ…å ±DBæ¤œç´¢"])

@st.cache_data
def fetch_table(table_name):
    url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json())
    else:
        st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}")
        return pd.DataFrame()

# --- ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–¢æ•° ---
def batch_upload_csv_to_supabase(file_path, table):
    if not os.path.exists(file_path):
        st.warning(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return
    try:
        df = pd.read_csv(file_path)

        # ãƒ­ãƒƒãƒˆéšå±¤ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆlot1, price1, lot2, price2...ï¼‰ã‹ã‚‰ lot_levels ã‚’ä½œæˆ
        if table == "products":
            lot_cols = [col for col in df.columns if col.startswith("lot") and not col.endswith("price")]
            lot_levels = []
            for _, row in df.iterrows():
                levels = []
                for i in range(1, 6):  # æœ€å¤§5æ®µéšã¾ã§å¯¾å¿œ
                    lot_col = f"lot{i}"
                    price_col = f"price{i}"
                    if lot_col in df.columns and price_col in df.columns:
                        lot = row.get(lot_col)
                        price = row.get(price_col)
                        if pd.notna(lot) and pd.notna(price):
                            levels.append({"lot": int(lot), "price": float(price)})
                row["lot_levels"] = json.dumps(levels, ensure_ascii=False)
            df = df.drop(columns=[col for col in df.columns if col.startswith("lot") or col.startswith("price")], errors="ignore")
        df["jan"] = df["jan"].astype(str).str.strip()
        df = df.drop_duplicates(subset="jan", keep="last")
        for _, row in df.iterrows():
            requests.post(
                f"{SUPABASE_URL}/rest/v1/{table}?on_conflict=jan",
                headers=HEADERS,
                json=row.where(pd.notnull(row), None).to_dict()
            )
        st.success(f"âœ… {table} ãƒ†ãƒ¼ãƒ–ãƒ«ã« {len(df)} ä»¶ã‚’ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"âŒ {table} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# --- æœ€é©ãªç™ºæ³¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç†ç”±ã‚’AIçš„ã«æç¤ºã™ã‚‹é–¢æ•° ---
def suggest_optimal_order(jan, need_qty, purchase_df):
    purchase_df = purchase_df[purchase_df["jan"] == jan].copy()
    if purchase_df.empty:
        return None, "ä»•å…¥å€™è£œãŒå­˜åœ¨ã—ã¾ã›ã‚“"
    
    best_plan = None
    reason = ""
    for _, row in purchase_df.iterrows():
        lot = row["order_lot"]
        price = row["price"]
        supplier = row["supplier"]
        if lot <= 0:
            continue
        units = -(-need_qty // lot)  # ceiling division
        total_price = units * lot * price
        if (best_plan is None) or (total_price < best_plan["total"]):
            best_plan = {
                "supplier": supplier,
                "lot": lot,
                "price": price,
                "units": units,
                "total": total_price
            }
            reason = f"ç™ºæ³¨æ•° {need_qty} ã«å¯¾ã—ã¦ã€{supplier} ã®ãƒ­ãƒƒãƒˆ {lot} ã§ {units} ã‚»ãƒƒãƒˆæ³¨æ–‡ â†’ åˆè¨ˆ {total_price:.0f}å†† ãŒæœ€å®‰ã§ã™"
    return best_plan, reason
