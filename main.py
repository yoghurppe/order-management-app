import streamlit as st
import pandas as pd
import requests
import os
import json
import urllib.parse

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–¢æ•°ï¼ˆæœ€é©åŒ–ï¼‰ ---
def batch_upload_csv_to_supabase(file_path, table):
    if not os.path.exists(file_path):
        st.warning(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return
    try:
        df = pd.read_csv(file_path)

        if table == "sales":
            rename_cols = {
                "ã‚¢ã‚¤ãƒ†ãƒ ": "jan",
                "è²©å£²æ•°é‡": "quantity_sold",
                "ç¾åœ¨ã®æ‰‹æŒæ•°é‡": "stock_total",
                "ç¾åœ¨ã®åˆ©ç”¨å¯èƒ½æ•°é‡": "stock_available",
                "ç¾åœ¨ã®æ³¨æ–‡æ¸ˆæ•°é‡": "stock_ordered"
            }
            df.rename(columns=rename_cols, inplace=True)

            for col in ["quantity_sold", "stock_total", "stock_available", "stock_ordered"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).round().astype(int)

            df["jan"] = df["jan"].astype(str).str.strip()

            # ğŸ” å…¨å‰Šé™¤ï¼ˆidãŒã‚ã‚‹å‰æã§é«˜é€Ÿå‰Šé™¤ï¼‰
            res_del = requests.delete(f"{SUPABASE_URL}/rest/v1/{table}?id=gt.0", headers=HEADERS)
            st.write(f"ğŸ—‘ DELETE ALL FROM {table}: {res_del.status_code}")

        if table == "purchase_data":
            for col in ["order_lot", "price"]:
                if col in df.columns:
                    df[col] = (df[col].astype(str).str.replace(",", "")
                                    .pipe(pd.to_numeric, errors="coerce")
                                    .fillna(0))
                    if col == "order_lot":
                        df[col] = df[col].round().astype(int)

            if "jan" in df.columns:
                df["jan"] = pd.to_numeric(df["jan"], errors="coerce").fillna(0).astype("int64").astype(str).str.strip()

            # ğŸ” å…¨å‰Šé™¤ï¼ˆidãŒã‚ã‚‹å‰æã§é«˜é€Ÿå‰Šé™¤ï¼‰
            res_del = requests.delete(f"{SUPABASE_URL}/rest/v1/{table}?id=gt.0", headers=HEADERS)
            st.write(f"ğŸ—‘ DELETE ALL FROM {table}: {res_del.status_code}")

        df = df.drop_duplicates(subset=["jan", "supplier"] if "supplier" in df.columns else "jan", keep="last")

        st.info(f"ğŸ”„ {table} ã« {len(df)} ä»¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        progress = st.progress(0)
        batch_size = 500
        total = len(df)

        for i in range(0, total, batch_size):
            batch = df.iloc[i:i+batch_size].where(pd.notnull(df.iloc[i:i+batch_size]), None).to_dict(orient="records")
            res = requests.post(
                f"{SUPABASE_URL}/rest/v1/{table}",
                headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                json=batch
            )
            if res.status_code not in [200, 201]:
                st.error(f"âŒ ãƒãƒƒãƒPOSTå¤±æ•— ({i} ä»¶ç›®ã€œ): {res.status_code} {res.text}")
                return
            progress.progress(min((i + batch_size) / total, 1.0))

        st.success(f"âœ… {table} ãƒ†ãƒ¼ãƒ–ãƒ«ã« {total} ä»¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"âŒ {table} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# --- ç™ºæ³¨åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
st.header("ğŸ§  ç™ºæ³¨å¯¾è±¡å•†å“ã®AIåˆ¤å®š")

@st.cache_data
def fetch_table(table_name):
    url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json())
    else:
        st.error(f"âŒ {table_name} ã®å–å¾—ã«å¤±æ•—: {res.text}")
        return pd.DataFrame()

df_sales = fetch_table("sales")
df_purchase = fetch_table("purchase_data")

if df_sales.empty or df_purchase.empty:
    st.info("è²©å£²å®Ÿç¸¾ã¾ãŸã¯ä»•å…¥ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
    st.stop()

# æ•´å½¢
df_sales["jan"] = df_sales["jan"].astype(str).str.strip()
df_purchase["jan"] = df_purchase["jan"].astype(str).str.strip()

results = []

for _, row in df_sales.iterrows():
    jan = row["jan"]
    sold = row.get("quantity_sold", 0)
    stock = row.get("stock_total", 0)
    need_qty = max(sold - stock, 0)
    if need_qty <= 0:
        continue

    # è©²å½“JANã®ä»•å…¥å€™è£œã‚’æŠ½å‡º
    purchase_options = df_purchase[df_purchase["jan"] == jan]
    if purchase_options.empty:
        continue

    # AIãƒ­ã‚¸ãƒƒã‚¯çš„ãªæœ€é©é¸æŠï¼ˆæœ€å®‰ã«ãªã‚‹çµ„ã¿åˆã‚ã›ã‚’é¸ã¶ï¼‰
    best_plan = None
    for _, opt in purchase_options.iterrows():
        lot = opt["order_lot"]
        price = opt["price"]
        supplier = opt["supplier"]
        if lot <= 0:
            continue
        units = -(-need_qty // lot)  # ceiling division
        total_cost = units * lot * price
        if best_plan is None or total_cost < best_plan["total"]:
            best_plan = {
                "jan": jan,
                "è²©å£²æ•°": sold,
                "åœ¨åº«": stock,
                "å¿…è¦æ•°": need_qty,
                "ãƒ­ãƒƒãƒˆ": lot,
                "å˜ä¾¡": price,
                "ã‚»ãƒƒãƒˆæ•°": units,
                "åˆè¨ˆ": total_cost,
                "ä»•å…¥å…ˆ": supplier
            }

    if best_plan:
        results.append(best_plan)

if results:
    result_df = pd.DataFrame(results)
    st.dataframe(result_df)
    csv = result_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="recommended_orders.csv", mime="text/csv")
else:
    st.info("ç¾åœ¨ã€ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
