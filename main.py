import streamlit as st
import pandas as pd
import requests

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ ---
mode = st.sidebar.radio("æ“ä½œã‚’é¸æŠ", ["ğŸ“¦ ç™ºæ³¨ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“š å•†å“æƒ…å ±DBæ¤œç´¢"])

@st.cache_data
def fetch_table(table_name):
    url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json())
    else:
        st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}")
        return pd.DataFrame()

# --- ç™ºæ³¨ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ ---
if mode == "ğŸ“¦ ç™ºæ³¨ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.header("ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.subheader("ğŸ§¾ å•†å“ãƒã‚¹ã‚¿ãƒ¼ï¼ˆproductsï¼‰")
    file1 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload1")
    if file1 is not None:
        try:
            df = pd.read_csv(file1)
            df["jan"] = df["jan"].astype(str).str.strip()
            df = df.drop_duplicates(subset="jan", keep="last")
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/products?on_conflict=jan",
                    headers=HEADERS,
                    json=row.where(pd.notnull(row), None).to_dict()
                )
            st.success("âœ… å•†å“ãƒã‚¹ã‚¿ãƒ¼ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ å•†å“ãƒã‚¹ã‚¿ãƒ¼CSVã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    st.subheader("ğŸ“ˆ è²©å£²å®Ÿç¸¾ï¼ˆsalesï¼‰")
    file2 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload2")
    if file2 is not None:
        try:
            df = pd.read_csv(file2)
            df["jan"] = df["jan"].astype(str).str.strip()
            df = df.drop_duplicates(subset="jan", keep="last")
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/sales?on_conflict=jan",
                    headers=HEADERS,
                    json=row.where(pd.notnull(row), None).to_dict()
                )
            st.success("âœ… è²©å£²å®Ÿç¸¾ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ è²©å£²å®Ÿç¸¾CSVã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    st.header("ğŸ“¦ ç™ºæ³¨åˆ¤å®š")
    df_products = fetch_table("products")
    df_sales = fetch_table("sales")

    if df_products.empty or df_sales.empty:
        st.warning("å•†å“ãƒã‚¹ã‚¿ãƒ¼ã¾ãŸã¯è²©å£²å®Ÿç¸¾ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    df_products["jan"] = df_products["jan"].astype(str).str.strip()
    df_sales["jan"] = df_sales["jan"].astype(str).str.strip()

    df_products = df_products.drop_duplicates(subset="jan", keep="last")
    df_sales = df_sales.drop_duplicates(subset="jan", keep="last")

    df = pd.merge(df_products, df_sales, on="jan", how="inner")

    def calculate_recommended_order(row):
        if row["quantity_sold"] > 0:
            lot = row.get("order_lot", 0)
            if pd.isna(lot) or lot <= 0:
                return 0
            return ((row["quantity_sold"] // lot) + 1) * lot
        return 0

    df["æ¨å¥¨ç™ºæ³¨æ•°"] = df.apply(calculate_recommended_order, axis=1)
    df["ç™ºæ³¨å¿…è¦"] = df["æ¨å¥¨ç™ºæ³¨æ•°"] > 0

    order_df = df[df["ç™ºæ³¨å¿…è¦"] == True][[
        "jan", "maker", "name", "quantity_sold", "order_lot", "æ¨å¥¨ç™ºæ³¨æ•°"
    ]]

    st.subheader("ğŸ“ ç™ºæ³¨å¯¾è±¡ãƒªã‚¹ãƒˆ")
    st.dataframe(order_df)

    if not order_df.empty:
        csv = order_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="order_list.csv",
            mime="text/csv"
        )

# --- å•†å“æƒ…å ±DBæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ ---
elif mode == "ğŸ“š å•†å“æƒ…å ±DBæ¤œç´¢":
    st.header("ğŸ“š å•†å“æƒ…å ±æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="item_master_upload")

    if file:
        try:
            df_upload = pd.read_csv(file)
            df_upload.columns = df_upload.columns.str.strip().str.lower()
            df_upload["jan"] = df_upload["jan"].astype(str).str.strip()

            if "å…¥æ•°" in df_upload.columns:
                df_upload["å…¥æ•°"] = pd.to_numeric(df_upload["å…¥æ•°"], errors="coerce").fillna(0).round().astype(int)

            df_upload = df_upload.drop_duplicates(subset="jan", keep="last")
            st.write("ğŸ§¾ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", df_upload.head())

            for _, row in df_upload.iterrows():
                clean_row = {}
                for k, v in row.items():
                    if pd.isnull(v):
                        clean_row[k] = None
                    elif k == "å…¥æ•°":
                        try:
                            clean_row[k] = int(float(v))
                        except:
                            clean_row[k] = 0
                    else:
                        clean_row[k] = v

                res = requests.post(
                    f"{SUPABASE_URL}/rest/v1/item_master?on_conflict=jan",
                    headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                    json=clean_row
                )
                st.write(f"ğŸ“¤ POST {clean_row.get('jan')} â†’ {res.status_code}: {res.text}")

            st.success("âœ… item_master ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")

            view_cols = ["jan", "æ‹…å½“è€…", "çŠ¶æ…‹", "ãƒ–ãƒ©ãƒ³ãƒ‰", "å•†å“å", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "é‡é‡", "å…¥æ•°", "ç™ºæ³¨æ¸ˆ"]
            available_cols = [col for col in view_cols if col in df_upload.columns]

            st.subheader("ğŸ“‹ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿å•†å“ä¸€è¦§")
            st.dataframe(df_upload[available_cols].sort_values(by="jan"))

            csv = df_upload[available_cols].to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="item_master_search.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

    df_master = fetch_table("item_master")
    if not df_master.empty:
        st.subheader("ğŸ“¦ item_masterä¸€è¦§ï¼ˆDBã‹ã‚‰å–å¾—ï¼‰")
        view_cols = ["jan", "æ‹…å½“è€…", "çŠ¶æ…‹", "ãƒ–ãƒ©ãƒ³ãƒ‰", "å•†å“å", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "é‡é‡", "å…¥æ•°", "ç™ºæ³¨æ¸ˆ"]
        available_cols = [col for col in view_cols if col in df_master.columns]
        st.dataframe(df_master[available_cols].sort_values(by="jan"))
