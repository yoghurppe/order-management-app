
import streamlit as st
import pandas as pd
import requests
import os
import datetime
import math

SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ğŸ“Š æ¯æ—¥è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ + ç™ºæ³¨åˆ¤å®š", layout="wide")
st.title("ğŸ“Š è²©å£²ãƒ‡ãƒ¼ã‚¿ (sales_daily) - 30æ—¥åˆ†ã®ã¿ä¿æŒ")

mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„", ["ğŸ“¤ è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“¦ ç™ºæ³¨AIåˆ¤å®šï¼ˆ30æ—¥é›†è¨ˆï¼‰"])

def delete_old_sales():
    cutoff = (datetime.date.today() - datetime.timedelta(days=30)).isoformat()
    res = requests.delete(f"{SUPABASE_URL}/rest/v1/sales_daily?date=lt.{cutoff}", headers=HEADERS)
    st.write(f"ğŸ§¹ 30æ—¥ã‚ˆã‚Šå‰ã®sales_dailyãƒ‡ãƒ¼ã‚¿å‰Šé™¤: {res.status_code}")

def batch_upload_daily_sales(file_path):
    try:
        df = pd.read_csv(file_path)

        df.rename(columns={
            "ã‚¢ã‚¤ãƒ†ãƒ ": "jan",
            "è²©å£²æ•°é‡": "quantity_sold",
            "ç¾åœ¨ã®æ‰‹æŒæ•°é‡": "stock_total",
            "ç¾åœ¨ã®åˆ©ç”¨å¯èƒ½æ•°é‡": "stock_available",
            "ç¾åœ¨ã®æ³¨æ–‡æ¸ˆæ•°é‡": "stock_ordered"
        }, inplace=True)

        for col in ["quantity_sold", "stock_total", "stock_available", "stock_ordered"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)

        df["jan"] = df["jan"].astype(str).str.strip()
        df["date"] = pd.to_datetime("today").normalize()

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã«å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
        delete_old_sales()

        df = df.drop_duplicates(subset=["jan", "date"], keep="last")

        batch_size = 500
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size].where(pd.notnull(df.iloc[i:i+batch_size]), None).to_dict(orient="records")
            res = requests.post(
                f"{SUPABASE_URL}/rest/v1/sales_daily",
                headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                json=batch
            )
            if res.status_code not in [200, 201]:
                st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {res.status_code} {res.text}")
                return
        st.success(f"âœ… {len(df)} ä»¶ sales_daily ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    except Exception as e:
        st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

if mode == "ğŸ“¤ è²©å£²ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.subheader("ğŸ“¤ æ¯æ—¥ã®è²©å£²CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆsales_dailyï¼‰")
    uploaded = st.file_uploader("sales_daily.csv ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
    if uploaded:
        tmp_path = "/tmp/sales_daily.csv"
        with open(tmp_path, "wb") as f:
            f.write(uploaded.read())
        batch_upload_daily_sales(tmp_path)

if mode == "ğŸ“¦ ç™ºæ³¨AIåˆ¤å®šï¼ˆ30æ—¥é›†è¨ˆï¼‰":
    st.header("ğŸ“¦ ç™ºæ³¨AIï¼ˆ30æ—¥é–“ã®åˆè¨ˆã‹ã‚‰åˆ¤å®šï¼‰")

    @st.cache_data(ttl=1)
    def fetch_table(name):
        url = f"{SUPABASE_URL}/rest/v1/{name}?select=*"
        res = requests.get(url, headers=HEADERS)
        return pd.DataFrame(res.json()) if res.status_code == 200 else pd.DataFrame()

    df_sales = fetch_table("sales_daily")
    df_purchase = fetch_table("purchase_data")

    if df_sales.empty or df_purchase.empty:
        st.warning("è²©å£² or ä»•å…¥ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        st.stop()

    df_sales["jan"] = df_sales["jan"].astype(str).str.strip()
    df_purchase["jan"] = df_purchase["jan"].astype(str).str.strip()

    agg_sales = df_sales.groupby("jan").agg({
        "quantity_sold": "sum",
        "stock_available": "last"
    }).reset_index()

    df_purchase["order_lot"] = pd.to_numeric(df_purchase["order_lot"], errors="coerce").fillna(0).astype(int)
    df_purchase["price"] = pd.to_numeric(df_purchase["price"], errors="coerce").fillna(0)

    results = []
    for _, row in agg_sales.iterrows():
        jan = row["jan"]
        sold = row["quantity_sold"]
        stock = row["stock_available"]
        expected_half_month_sales = sold * 0.5
        available_at_arrival = max(0, stock - expected_half_month_sales)
        need_qty = max(sold - available_at_arrival, 0)

        st.write(f"JAN: {jan}")
        st.write(f"  30æ—¥è²©å£²æ•°: {sold}, åˆ©ç”¨å¯èƒ½åœ¨åº«: {stock}")
        st.write(f"  ç´å“æ™‚åœ¨åº«äºˆæ¸¬: {available_at_arrival}, å¿…è¦ç™ºæ³¨æ•°: {need_qty}")

        if need_qty <= 0:
            continue

        options = df_purchase[df_purchase["jan"] == jan]
        if options.empty:
            continue

        options = options.sort_values(by="price")
        best_plan = None
        for _, opt in options.iterrows():
            lot = opt["order_lot"]
            price = opt["price"]
            supplier = opt.get("supplier", "ä¸æ˜")
            if pd.isna(lot) or pd.isna(price) or lot <= 0:
                continue

            sets = math.ceil(need_qty / lot)
            qty = sets * lot

            if best_plan is None or price < best_plan["å˜ä¾¡"]:
                best_plan = {
                    "jan": jan,
                    "è²©å£²æ•°": sold,
                    "åœ¨åº«": stock,
                    "ç™ºæ³¨æ•°": qty,
                    "å˜ä¾¡": price,
                    "ä»•å…¥å…ˆ": supplier
                }

        if best_plan:
            results.append(best_plan)

    if results:
        result_df = pd.DataFrame(results)
        st.success(f"âœ… ç™ºæ³¨å¯¾è±¡: {len(result_df)} ä»¶")
        st.dataframe(result_df)
        csv = result_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ç™ºæ³¨CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="orders_30days.csv", mime="text/csv")
    else:
        st.info("ç¾åœ¨ã€ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
