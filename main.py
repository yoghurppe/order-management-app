import streamlit as st
import pandas as pd
import requests
import os
import math
import re

SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

def fetch_table(table_name):
    headers = {
        **HEADERS,
        "Prefer": "count=exact"
    }
    dfs = []
    offset = 0
    limit = 1000

    while True:
        url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*&offset={offset}&limit={limit}"
        res = requests.get(url, headers=headers)
        if res.status_code == 416:
            break
        if res.status_code not in [200, 206]:
            st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—: {res.status_code} / {res.text}")
            return pd.DataFrame()
        data = res.json()
        if not data:
            break
        dfs.append(pd.DataFrame(data))
        offset += limit

    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()

def normalize_jan(x):
    try:
        if re.fullmatch(r"\d+(\.0+)?", str(x)):
            return str(int(float(x)))
        else:
            return str(x).strip()
    except:
        return ""

# å•†å“ãƒã‚¹ã‚¿ã‚’å–å¾—ï¼ˆdfãŒæœªå®šç¾©ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ï¼‰
df = fetch_table("items")

# è¡¨ç¤ºç”¨ã®åˆ—ã¨è¡¨ç¤ºåãƒãƒƒãƒ”ãƒ³ã‚°
view_cols = [
    "å•†å“ã‚³ãƒ¼ãƒ‰", "jan", "ãƒ©ãƒ³ã‚¯", "ãƒ–ãƒ©ãƒ³ãƒ‰", "å•†å“å", "å–æ‰±åŒºåˆ†",
    "åœ¨åº«", "åˆ©ç”¨å¯èƒ½", "ç™ºæ³¨æ¸ˆ", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "ç™ºæ³¨ãƒ­ãƒƒãƒˆ", "é‡é‡"
]
rename_map = {
    "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ã‚³ãƒ¼ãƒ‰/å•†å“ç¼–å·",
    "jan": "JAN",
    "ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯/ç­‰çº§",
    "ãƒ–ãƒ©ãƒ³ãƒ‰": "ãƒ–ãƒ©ãƒ³ãƒ‰/å“ç‰Œ",
    "å•†å“å": "å•†å“å/å•†å“åç§°",
    "å–æ‰±åŒºåˆ†": "å–æ‰±åŒºåˆ†/åˆ†ç±»",
    "åœ¨åº«": "åœ¨åº«/åº“å­˜",
    "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½/å¯ç”¨åº“å­˜",
    "ç™ºæ³¨æ¸ˆ": "ç™ºæ³¨æ¸ˆ/å·²è®¢è´­",
    "ä»•å…¥ä¾¡æ ¼": "ä»•å…¥ä¾¡æ ¼/è¿›è´§ä»·",
    "ã‚±ãƒ¼ã‚¹å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°/ç®±å…¥æ•°",
    "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ/è®¢è´­å•ä½",
    "é‡é‡": "é‡é‡/é‡é‡(g)"
}
available_cols = [col for col in view_cols if col in df.columns]

# å•†å“æƒ…å ±CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
st.header("ğŸ“¤ å•†å“æƒ…å ±CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_file = st.file_uploader("å•†å“æƒ…å ±CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")

if uploaded_file is not None:
    df_upload = pd.read_csv(uploaded_file)

    def preprocess_item_master(df):
        df.rename(columns={
            "UPCã‚³ãƒ¼ãƒ‰": "jan",
            "è¡¨ç¤ºå": "å•†å“å",
            "ãƒ¡ãƒ¼ã‚«ãƒ¼å": "ãƒ–ãƒ©ãƒ³ãƒ‰",
            "ã‚¢ã‚¤ãƒ†ãƒ å®šç¾©åŸä¾¡": "ä»•å…¥ä¾¡æ ¼",
            "ã‚«ãƒ¼ãƒˆãƒ³å…¥æ•°": "ã‚±ãƒ¼ã‚¹å…¥æ•°",
            "ç™ºæ³¨ãƒ­ãƒƒãƒˆ": "ç™ºæ³¨ãƒ­ãƒƒãƒˆ",
            "ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é‡é‡(g)": "é‡é‡",
            "æ‰‹æŒ": "åœ¨åº«",
            "åˆ©ç”¨å¯èƒ½": "åˆ©ç”¨å¯èƒ½",
            "æ³¨æ–‡æ¸ˆ": "ç™ºæ³¨æ¸ˆ",
            "åå‰": "å•†å“ã‚³ãƒ¼ãƒ‰",
            "å•†å“ãƒ©ãƒ³ã‚¯": "ãƒ©ãƒ³ã‚¯"
        }, inplace=True)
        df["jan"] = df["jan"].apply(normalize_jan)
        return df

    df_upload = preprocess_item_master(df_upload)

    if "jan" in df_upload.columns and "ãƒ©ãƒ³ã‚¯" in df_upload.columns:
        for _, row in df_upload.iterrows():
            payload = {
                "rank": row["ãƒ©ãƒ³ã‚¯"]
            }
            res = requests.patch(
                f"{SUPABASE_URL}/rest/v1/items?jan=eq.{row['jan']}",
                headers={**HEADERS, "Content-Type": "application/json"},
                json=payload
            )
            if res.status_code not in [200, 204]:
                st.error(f"JAN {row['jan']} ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.status_code} / {res.text}")
        st.success("CSVã‹ã‚‰ã®ãƒ©ãƒ³ã‚¯æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ")
    else:
        st.error("CSVã«å¿…è¦ãª 'jan' ã¾ãŸã¯ 'å•†å“ãƒ©ãƒ³ã‚¯'ï¼ˆâ†’ãƒ©ãƒ³ã‚¯ï¼‰åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
