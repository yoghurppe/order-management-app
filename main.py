import streamlit as st
import pandas as pd
import requests

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ ---
mode = st.sidebar.radio("æ“ä½œã‚’é¸æŠ", ["ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“¦ ç™ºæ³¨åˆ¤å®š"])

# --- CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ ---
if mode == "ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.header("ğŸ§¾ å•†å“ãƒã‚¹ã‚¿ãƒ¼ï¼ˆproductsï¼‰")
    file1 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload1")
    if file1 is not None:
        try:
            df = pd.read_csv(file1)
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/products?on_conflict=jan",
                    headers=HEADERS,
                    json=row.to_dict()
                )
            st.success("âœ… å•†å“ãƒã‚¹ã‚¿ãƒ¼ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ å•†å“ãƒã‚¹ã‚¿ãƒ¼CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    st.header("ğŸ“ˆ è²©å£²å®Ÿç¸¾ï¼ˆsalesï¼‰")
    file2 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload2")
    if file2 is not None:
        try:
            df = pd.read_csv(file2)
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/sales?on_conflict=jan",
                    headers=HEADERS,
                    json=row.to_dict()
                )
            st.success("âœ… è²©å£²å®Ÿç¸¾ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ è²©å£²å®Ÿç¸¾CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# --- ç™ºæ³¨åˆ¤å®šãƒ¢ãƒ¼ãƒ‰ ---
elif mode == "ğŸ“¦ ç™ºæ³¨åˆ¤å®š":
    st.header("ğŸ“¦ ç™ºæ³¨å¯¾è±¡å•†å“ãƒªã‚¹ãƒˆ")

    @st.cache_data
    def fetch_table(table_name):
        url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            return pd.DataFrame(res.json())
        else:
            st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}")
            return pd.DataFrame()

    df_products = fetch_table("products")
    df_sales = fetch_table("sales")

    if df_products.empty or df_sales.empty:
        st.warning("å•†å“ãƒã‚¹ã‚¿ãƒ¼ã¾ãŸã¯è²©å£²å®Ÿç¸¾ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # JANã‚³ãƒ¼ãƒ‰ã®å‹ã‚’æƒãˆã‚‹å‡¦ç†ã¯çµåˆã®ã€å‰ã€‘ã«å…¥ã‚Œã‚‹ï¼
    df_products["jan"] = df_products["jan"].astype(str).str.strip()
    df_sales["jan"] = df_sales["jan"].astype(str).str.strip()

    # çµåˆï¼ˆã“ã“ã§åˆã‚ã¦joinã•ã‚Œã‚‹ï¼‰
    df = pd.merge(df_products, df_sales, on="jan", how="inner")

    def calculate_recommended_order(row):
        if row["quantity_sold"] > 0:
            lot = row.get("order_lot", 0)
            if pd.isna(lot) or lot <= 0:
                return 0
            return ((row["quantity_sold"] // lot) + 1) * lot
        return 0

    df["æ¨å¥¨ç™ºæ³¨æ•°"] = df.apply(calculate_recommended_order, axis=1)
    df["ç™ºæ³¨å¿…è¦"] = df["æ¨å¥¨ç™ºæ³¨æ•°"] > 0

    order_df = df[df["ç™ºæ³¨å¿…è¦"] == True][[
        "jan", "maker", "name", "quantity_sold", "order_lot", "æ¨å¥¨ç™ºæ³¨æ•°"
    ]]

    st.subheader("ğŸ“ ç™ºæ³¨å¯¾è±¡ãƒªã‚¹ãƒˆ")
    st.dataframe(order_df)

    if not order_df.empty:
        csv = order_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="order_list.csv",
            mime="text/csv"
        )
