import streamlit as st
import pandas as pd
import requests

# Supabaseè¨­å®š
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

st.set_page_config(page_title="ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ“¦ ç™ºæ³¨ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆç‰ˆï¼‰")

# --- ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ ---
mode = st.sidebar.radio("æ“ä½œã‚’é¸æŠ", ["ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“¦ ç™ºæ³¨åˆ¤å®š", "ğŸ“š å•†å“æƒ…å ±DBæ¤œç´¢"])

# --- CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ ---
if mode == "ğŸ“¤ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.header("ğŸ§¾ å•†å“ãƒã‚¹ã‚¿ãƒ¼ï¼ˆproductsï¼‰")
    file1 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload1")
    if file1 is not None:
        try:
            df = pd.read_csv(file1)
            df["jan"] = df["jan"].astype(str).str.strip()
            df = df.drop_duplicates(subset="jan", keep="last")
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/products?on_conflict=jan",
                    headers=HEADERS,
                    json=row.where(pd.notnull(row), None).to_dict()
                )
            st.success("âœ… å•†å“ãƒã‚¹ã‚¿ãƒ¼ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ å•†å“ãƒã‚¹ã‚¿ãƒ¼CSVã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    st.header("ğŸ“ˆ è²©å£²å®Ÿç¸¾ï¼ˆsalesï¼‰")
    file2 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="upload2")
    if file2 is not None:
        try:
            df = pd.read_csv(file2)
            df["jan"] = df["jan"].astype(str).str.strip()
            df = df.drop_duplicates(subset="jan", keep="last")
            for _, row in df.iterrows():
                requests.post(
                    f"{SUPABASE_URL}/rest/v1/sales?on_conflict=jan",
                    headers=HEADERS,
                    json=row.where(pd.notnull(row), None).to_dict()
                )
            st.success("âœ… è²©å£²å®Ÿç¸¾ã‚’ Supabase ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"âŒ è²©å£²å®Ÿç¸¾CSVã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# --- ç™ºæ³¨åˆ¤å®šãƒ¢ãƒ¼ãƒ‰ ---
elif mode == "ğŸ“¦ ç™ºæ³¨åˆ¤å®š":
    st.header("ğŸ“¦ ç™ºæ³¨å¯¾è±¡å•†å“ãƒªã‚¹ãƒˆ")

    def fetch_table(table_name):
        url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            return pd.DataFrame(res.json())
        else:
            st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}")
            return pd.DataFrame()

    df_products = fetch_table("products")
    df_sales = fetch_table("sales")

    if df_products.empty or df_sales.empty:
        st.warning("å•†å“ãƒã‚¹ã‚¿ãƒ¼ã¾ãŸã¯è²©å£²å®Ÿç¸¾ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    df_products["jan"] = df_products["jan"].astype(str).str.strip()
    df_sales["jan"] = df_sales["jan"].astype(str).str.strip()

    df_products = df_products.drop_duplicates(subset="jan", keep="last")
    df_sales = df_sales.drop_duplicates(subset="jan", keep="last")

    df = pd.merge(df_products, df_sales, on="jan", how="inner")

    def calculate_recommended_order(row):
        if row["quantity_sold"] > 0:
            lot = row.get("order_lot", 0)
            if pd.isna(lot) or lot <= 0:
                return 0
            return ((row["quantity_sold"] // lot) + 1) * lot
        return 0

    df["æ¨å¥¨ç™ºæ³¨æ•°"] = df.apply(calculate_recommended_order, axis=1)
    df["ç™ºæ³¨å¿…è¦"] = df["æ¨å¥¨ç™ºæ³¨æ•°"] > 0

    order_df = df[df["ç™ºæ³¨å¿…è¦"] == True][[
        "jan", "maker", "name", "quantity_sold", "order_lot", "æ¨å¥¨ç™ºæ³¨æ•°"
    ]]

    st.subheader("ğŸ“ ç™ºæ³¨å¯¾è±¡ãƒªã‚¹ãƒˆ")
    st.dataframe(order_df)

    if not order_df.empty:
        csv = order_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="order_list.csv",
            mime="text/csv"
        )

# --- å•†å“æƒ…å ±DBæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ ---
elif mode == "ğŸ“š å•†å“æƒ…å ±DBæ¤œç´¢":
    st.header("ğŸ“š å•†å“æƒ…å ±æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")

    # --- CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
    st.subheader("ğŸ“¤ item_master ãƒ†ãƒ¼ãƒ–ãƒ«ã¸CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="item_master_upload")

    if file:
        try:
            df_upload = pd.read_csv(file)
            df_upload.columns = df_upload.columns.str.strip().str.lower()
            df_upload["jan"] = df_upload["jan"].astype(str).str.strip()

            # å…¥æ•°ã‚«ãƒ©ãƒ ã‚’å®‰å…¨ã«æ•´æ•°åŒ–ï¼ˆæ–‡å­—åˆ—ãƒ»å°æ•° â†’ æ•´æ•°ï¼‰
            if "å…¥æ•°" in df_upload.columns:
                df_upload["å…¥æ•°"] = pd.to_numeric(df_upload["å…¥æ•°"], errors="coerce").fillna(0).round().astype(int)

            df_upload = df_upload.drop_duplicates(subset="jan", keep="last")
            st.write("ğŸ§¾ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", df_upload.head())
            for _, row in df_upload.iterrows():
                clean_row = {}
                for k, v in row.items():
                    if pd.isnull(v):
                        clean_row[k] = None
                    elif k == "å…¥æ•°":
                        try:
                            clean_row[k] = int(float(v))
                        except:
                            clean_row[k] = 0
                    else:
                        clean_row[k] = v

                res = requests.post(
                    f"{SUPABASE_URL}/rest/v1/item_master?on_conflict=jan",
                    headers={**HEADERS, "Prefer": "resolution=merge-duplicates"},
                    json=clean_row
                )
                st.write(f"ğŸ“¤ POST {clean_row.get('jan')} â†’ {res.status_code}: {res.text}")
            st.success("âœ… item_master ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")


    def fetch_table(table_name):
        url = f"{SUPABASE_URL}/rest/v1/item_master?select=*"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            return pd.DataFrame(res.json())
        else:
            st.error(f"{table_name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}")
            return pd.DataFrame()

    df = fetch_table("item_master")

    if df.empty:
        st.warning("å•†å“æƒ…å ±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    df["jan"] = df["jan"].astype(str).str.strip()
    df = df.drop_duplicates(subset="jan", keep="last")

    # æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ UI
    col1, col2, col3 = st.columns(3)
    with col1:
        jan_query = st.text_input("JANã§æ¤œç´¢")
        status_filter = st.selectbox("çŠ¶æ…‹", options=["ã™ã¹ã¦"] + sorted(df["çŠ¶æ…‹"].dropna().unique().tolist()))
    with col2:
        æ‹…å½“_filter = st.selectbox("æ‹…å½“è€…", options=["ã™ã¹ã¦"] + sorted(df["æ‹…å½“è€…"].dropna().unique().tolist()))
        brand_filter = st.selectbox("ãƒ–ãƒ©ãƒ³ãƒ‰", options=["ã™ã¹ã¦"] + sorted(df["ãƒ–ãƒ©ãƒ³ãƒ‰"].dropna().unique().tolist()))
    with col3:
        keyword = st.text_input("å•†å“åã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰")
        ç™ºæ³¨æ¸ˆ_filter = st.checkbox("ç™ºæ³¨æ¸ˆï¼ˆ0ä»¥å¤–ï¼‰")

    # æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if jan_query:
        df = df[df["jan"].str.contains(jan_query)]
    if status_filter != "ã™ã¹ã¦":
        df = df[df["çŠ¶æ…‹"] == status_filter]
    if æ‹…å½“_filter != "ã™ã¹ã¦":
        df = df[df["æ‹…å½“è€…"] == æ‹…å½“_filter]
    if brand_filter != "ã™ã¹ã¦":
        df = df[df["ãƒ–ãƒ©ãƒ³ãƒ‰"] == brand_filter]
    if keyword:
        df = df[df["å•†å“å"].str.contains(keyword, case=False, na=False)]
    if ç™ºæ³¨æ¸ˆ_filter:
        df = df[df["ç™ºæ³¨æ¸ˆ"] != 0]

    # è¡¨ç¤ºåˆ—é¸æŠ
    view_cols = ["jan", "æ‹…å½“è€…", "çŠ¶æ…‹", "ãƒ–ãƒ©ãƒ³ãƒ‰", "å•†å“å", "ä»•å…¥ä¾¡æ ¼", "ã‚±ãƒ¼ã‚¹å…¥æ•°", "é‡é‡", "ç™ºæ³¨æ¸ˆ"]
    st.dataframe(df[view_cols].sort_values(by="jan"))

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not df.empty:
        csv = df[view_cols].to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="item_master_search.csv",
            mime="text/csv"
        )
